---
title: "Compositional analysis of microbiome data"
author: "Xin (David) Zhao"
date: "Last edited `r format(Sys.time(), '%d %B %Y')`"
knit: (function(inputFile, encoding) {
      out_dir <- 'docs';
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_file=file.path(dirname(inputFile), out_dir, 'index.html'))})
output:
  html_document:
    # theme: cosmo
    highlight: pygments
    df_print: paged
    toc: TRUE
    toc_float: TRUE
    collapsed: FALSE
    number_sections: TRUE
    fig_width: 7
    fig_height: 6
    fig_caption: TRUE
--- 

<html>
<head>
<style>

h1{
 color: black;
 font-family: helvetica;
 font-size: 200%
}

h2{
 color: #333333;  
 font-family: helvetica;
 font-size: 120%; 
}

p {
 color: #333333;
 font-family: helvetica;
 font-size: 100%;
}

</style>
</head>
</html>

```

```{r setup, include = FALSE}
# set options for the entire document 
knitr::opts_chunk$set(fig.align = 'center', 
                      fig.dim =c(6,4), 
                      dev="png",
                      echo=TRUE, #display code in output document 
                      error=FALSE,
                      message=FALSE) #stop render when error occurs   
```


This project was built with R `r getRversion()`.
```{r load libraries, message=FALSE, warning=FALSE}

library(ALDEx2)
library(vegan)
library(xtable)  #make result table
library(zCompositions) # replace 0 values 
library(compositions) 
library(tidyverse)

```

## Introduction 

- Compositional data 
- Aitchison simplex 
- A family of log-ratio transformation 
- How to deal zeros in compositional data analysis
- Statistical tools for compositional data analysis


## Outline of steps to compare between groups using ALDEx2 package 

1. Download raw microbiome data and metadata 
2. Preprocess input data - replace 0 values using the `zCompositions` package 
3. Convert data to proportions 
4. Perform abundance and sample filtering and deal sparsity 
5. Perform the `clr` data transform 
6. Perform the singular value decomposition using the function `prcomp()` 
7. Display the results of PCoA by using `biplot()` or `coloredBiplot()` 
8. Visualization for exploratory data analysis 
9. Perform the Welch's t and Wilcoxon Rank Sum Test using `aldex.ttest()` 
10. Estimate effect size using the function `aldex.effect()` 
11. Merge all data into one object and make a data frame for result viewing and downstream analysis 
12. Difference plot, effect size and effect plots 

Steps through 1 to 8 are data exploratory while steps through 9 to 12 are differential abundance analysis by `ALDEx2` 


## Scripts to implement above procedures 

### Step 1. Download raw microbiome data and metadata  

The microbiome OTU table and metadata was retrieved from [ML Repo] (https://knights-lab.github.io/MLRepo/docs/turnbaugh_lean_obese_all.html)  

```{r}

# raw OTU table
raw_otu <- read.csv(file = "https://knights-lab.github.io/MLRepo/datasets/turnbaugh/refseq/otutable.txt",
                    header=T,
                    sep = "")

```
Read in the metadata from URL. 

```{r}

# metadata 

meta <- read.csv(file = "https://knights-lab.github.io/MLRepo/datasets/turnbaugh/task-obese-lean-all.txt",
         header = TRUE,
         sep = "") 

```
The metadata contains `r dim(meta)[1]` samples. `Var` indicates the independent, binary variable of interest, `Lean` and `Obese`. 


### Step 2. Preprocess input data - replace 0 values using the `zCompositions` package  

Convert the raw OTU table, with samples being rows while OTU being columns. 
```{r}

t_raw_otu <- raw_otu %>% 
  gather(key = "sample",
         value = "reads",
         3:ncol(.)) %>% 
  dplyr::select(-ID) %>% 
  spread(key = names(.)[1],
         value = "reads") %>% 
  column_to_rownames("sample")  # convert column to row id 


```


Replace 0 values using the `zCompositions` package. 

Inspect whether any NA (missing values) exits; replace NA with 0 values if any. Follow the instructions introduced [here] (https://www.r-bloggers.com/2019/09/handling-missing-values-in-r-using-tidyr/). 

```{r}

sum(is.na(t_raw_otu)) # check number of missing values 

na_t_raw_otu <- t_raw_otu %>% 
  mutate_all(replace_na, 0) # replace NA with 0 value 

sum(is.na(na_t_raw_otu)) # check number of missing values afterwards 


```

Evaluate 0/missing values patterns in the OTU table with `zPatterns()` from the `zCompositions` package. 
```{r zPatterns}

pattern.ID <- zPatterns(na_t_raw_otu, 
          label = 0, # identify zero percentages 
          plot=TRUE,
          show.means = FALSE,
          bar.ordered = c(TRUE, TRUE),
          bar.labels = TRUE)  

```


Apply `cmultRepl()` from the `zCompositions` package to replace 0 values with the count zero multiplicative method and output counts. Error information appear and the function stops. Therefore, remove samples that are zeros for every OTU. And then implement the above function again. 
```{r drop OTU with all zeros, collapse=TRUE} 

rm_na_t_raw_otu <- na_t_raw_otu[pattern.ID != 281, ] 


rp_rm_na_t_raw_otu <- cmultRepl(rm_na_t_raw_otu, 
          method = "CZM",
          output = "p-counts",  # pseudo-counts 
          z.warning=0.8)  

```


### Step 3. Convert data to proportions  

Transpose the resulting data frame to OTU X sample format. 

```{r} 

pcount_otu <- rp_rm_na_t_raw_otu %>% 
  rownames_to_column("sample") %>% 
  gather(key = "otu", value = "reads", -sample) %>% 
  spread(key = "sample", value = "reads") %>% 
  column_to_rownames("otu") 

head(pcount_otu)
```

Calculate total pcount throughout samples. 
```{r prop}

pcount_otu %>% 
  rownames_to_column("otu") %>% 
  gather(key= "sample", value = "pcount", -otu) %>% 
  group_by(sample) %>% 
  summarise(total = sum(pcount), .groups = "drop") 

```


Calculate proportions based on pseudo counts.  
```{r, collapse=TRUE}

prop_pcount_otu <- pcount_otu %>% 
  map_dfr(function(x) x/sum(x)) 

colSums(prop_pcount_otu) == 1 # check if sum to each column equals 1 
  
rownames(prop_pcount_otu) <- rownames(pcount_otu)  # assign row names to the resulting data frame 

```

### Step 4. Perform abundance and sample filtering and deal sparsity 

Filter proportional OTU data to remove all OTU that are less than 0.01% in any samples. 

```{r filtering}

otu_id_dropped <- prop_pcount_otu %>% 
  rownames_to_column("otu") %>% 
  gather(key = "sample", value="prop", -otu) %>% 
  group_by(otu) %>%
  summarise(max = max(prop)) %>% 
  ungroup() %>% 
  filter(max < 0.0001) %>% # minimal proportional threshold 0.01% 
  pull(otu)
  
# remove OTU not passing 0.01% threshold 
pcount_otu_fl <- pcount_otu %>% 
  rownames_to_column("otu") %>% 
  filter(!otu %in% otu_id_dropped) %>% 
  column_to_rownames("otu")

```


### Step 5. Perform the clr data transformation

The formula of `clr` is ... 

```{r}

# extract the descendingly ordered taxa 
desc_otu_id <- pcount_otu_fl %>% 
  rownames_to_column("otu") %>% 
  gather(key = "sample", value = "pcount", -otu) %>% 
  group_by(otu) %>% 
  summarise(total = sum(pcount)) %>% 
  arrange(desc(total)) %>% 
  pull(otu)


# re-order the pcount OTU table 
pcount_otu_fl_desc <- pcount_otu_fl[desc_otu_id, ]


# clr transformation 
pcount_otu_fl_desc_clr <- t(apply(pcount_otu_fl_desc, 2, function(x) {log(x) - mean(log(x))}))  

pcount_otu_fl_desc_clr <- data.frame(pcount_otu_fl_desc_clr)  # convert to data frame format 


```

### Step 6. Perform the singular value decomposition using the fucntion prcomp() 

Conduct principal component analysis on the compositional data set using `prcomp()` 

```{r pca}

pca_clr <- prcomp(pcount_otu_fl_desc_clr) 

summary(pca_clr) 

```



### Step 7. Display the results of PCA by ggplot2 

```{r PCA plot} 

# extract PC1-2 for all samples 
pc2 <- data.frame(pca_clr$x[,1:2]) 

# merge metadata 
pc2_meta <- pc2 %>% 
  rownames_to_column("sample") %>% 
  inner_join(meta, by = c("sample" = "X.SampleID")) %>% 
  rename(is_obese = Var) %>% 
  mutate(is_obese = factor(is_obese, levels = c("Obese", "Lean"))) %>% 
  select(-ControlVar)


# plotting with ggplot2 
ggplot(pc2_meta, aes(x=PC1, y=PC2, color=is_obese, fill=is_obese))+
  geom_point(alpha = 0.5) +
  theme_classic()


```


### Compositional scree plot 
Use scree plot to display the proportion of the total variation in the data set that is explained by each of the components in a principal component analysis. Create the scree plot using `screeplot()` function. 

```{r scree plot}

layout(matrix(c(1,2), 1, 2, byrow = T),
       widths = c(6,4),
       heights = c(6,4))
par(mgp = c(2,0.5,0))
screeplot(pca_clr, type = "line", main = "Scree plot") 
screeplot(pca_clr, type = "barplot", main = "Scree plot") 


```

### Compositional cluster dendrogram 

Conduct a cluster analysis and plot cluster dendrogram on the log-ratio-transformed data. Use Euclidian distance because the Aitchison transformed data are linearly related, but all distances should be calculated from the ratios. 

```{r}

# calculate distance matrix 
dist <- dist(pcount_otu_fl_desc_clr, method = "euclidian") 


# cluster the data 
hc <- hclust(dist, method = "ward.D2") 

hc 


# plot the dendrogram 
plot(hc, cex=1.0)


```



### Compositional barplot 

```{r}

# reorder according to clustering structure 
pcount_otu_fl_reorder <- pcount_otu_fl[ ,hc$order]



# bar plot 
re_order_acomp <- acomp(t(pcount_otu_fl_reorder))
par(mfrow = c(1,2)) 
colors <- rainbow(10)

barplot(re_order_acomp, legend.text = F, col=colors,
        axisnames=F,
        border=NA,
        xpd = T)
plot(1,2, pch = 1, lty=1, ylim=c(-10, 10),
     type= "n", axes = FALSE, ann=FALSE) 

legend(x = "center", 
       legend = desc_otu_id,
       col = colors,
       lwd = 5,
       cex = .6,
       border = NULL)


```


### Step 9. Perform the Welch's t and Wilcoxon Rank Sum Test using `aldex.ttest()` 

ALDEx2 needs the input data with taxa by samples formats. 
```{r input aldex2}

# metadata 
is.obese <- meta %>% 
  rename(sample = X.SampleID, 
         is_obese = Var) %>% 
  select(-ControlVar)

# otu count data 
na_t_raw_otu2 <- na_t_raw_otu %>% 
  rownames_to_column("sample") 

# merge metadata and count data 
groups <- na_t_raw_otu2 %>% 
  inner_join(is.obese, by= "sample") %>% 
  pull(is_obese) 

length(groups)  # 142 samples 

groups <- factor(groups)


# subset count data 
na_t_raw_otu3 <- na_t_raw_otu2 %>% 
  inner_join(is.obese, by= "sample") %>% 
  select(-is_obese) %>% 
  gather(key = "otu", value= "reads", -sample) %>% 
  spread(key = "sample", value = "reads") %>% 
  column_to_rownames("otu") 

ncol(na_t_raw_otu3) # 142 samples 

# input count data to ALDEX2 
aldex_raw_count <- na_t_raw_otu3 


```

Generate instances of the centered log-ratio transformed values using the function `aldex.clr()`  

The function `aldex.clr()` has three input: count table, number of Monte-Carlo instances, and level of verbosity (TRUE or FALSE). The package authors recommend 128 or more `mc.samples` for the t-test, 1000 for a rigorous effect size calculation, and at least 16 for ANOVA. 

```{r aldex clr}

vdr <- aldex.clr(aldex_raw_count,
                 groups,
                 mc.samples = 128,
                 verbose = TRUE)  

```

Perform the Welch's and Wilcoxon rank sum test using `aldex.ttest()`

The function `aldex.ttest()` returns the values of `we.ep` (expected p-value of Welch's t test), `we.eBH` (expected Benjamini-Hochberg corrected p-value of Welch's t test), `wi.ep` (expected p-value of Wilcoxon rank sum test), and `wi.eBH` (expected Benjamini-Hochberg corrected p-value of Wilcoxon rank sum test)

The function, `aldex.glm()` is alternative to `aldex.ttest()` which implement Kruskal-Wallis test. However, it is slow. 

```{r} 

vdr_t <- aldex.ttest(vdr, paired.test=FALSE, hist.plot=FALSE, verbose=FALSE)   

head(vdr_t)
```

Estimate effect size using the function `aldex.effect()`

The `aldex.effect()` function estimates effect size and the within and between condition values in the case of two conditions.

It has 3 arguments: 
- the aldex object from aldex.clr()
- a flag indicating whether or not to include values for all samples are used as the denominator 
- the level of verbosity 

```{r effect size}

vdr_effect <- aldex.effect(vdr, include.sample.summary = FALSE, verbose = FALSE)

```

The function, `aldex.effect()` returns all values including, 
- rab.all  median clr value for all samples inthe feature 
- rab.win.VdrFecal  median clr value for the VdrFecal group of samples
- rba.win.VdrCecal  median clr value for the VdrCecal groups of samples 
- dif.btw  median difference in clr values beween VdrFecal and VdrCecal groups
- dif.win  median of the largest difference in clr values within VdrFecal and VdrCecal groups 
- effect  median effect size: diff.btw/max(diff.win) for all instances 
- overlap  proportion of effect size that overlaps 0: it is overlap between the Bayesian distribuiotn of rous VdrFecal and VdrCecal 

Merge all outputs into one single object and make a data frame for result viewing and downstream analysis 
```{r} 

vdr_all <- data.frame(vdr_t, vdr_effect)  


head(vdr_all)
```


Check any significant taxa between obese and lean conditions detected in both Welch's t-test and Wilcoxon rank sum tests. 
```{r sig taxa}

sig_by_both <- vdr_all %>% 
  filter(we.ep <= 0.05 & wi.ep <= 0.05)

sig_by_both 


```
Any taxa remain significant when p-values are adjusted for multiple testing correction using BH method. 

```{r pval sig}

sig_by_both_fdr <- vdr_all %>% 
  filter(we.eBH <= 0.05 & wi.eBH <= 0.05) 

sig_by_both_fdr 

```


Bland-Altman plot (also known as "difference plot")
The point underlying the method is that any two methods designing to measure the same property or parameter should have agree sufficiently closely, but not merely highly correlated. 

ALDEX2 provides a Bland-Altman (MA) style plot to graphically compare the degree of agreement of measures between median log2 between-condition difference and median log2 relative abundance. 

```{r MA plot}

aldex.plot(vdr_all, 
           type = "MA", # specifies plot type to be produced 
           test = "welch", # indicates using Welch's t test to calculate significance 
           cutoff.pval = 0.15, 
           all.cex = 0.7, # symbol size
           called.cex = 1.1, # specify the character expansion of points with FDR, q<= 0.1
           rare.col = "grey", # grey for rare taxa 
           called.col = "red")  # present those taxa that have a mean BH adjusted Wilcoxon rank sum test p-value of 0.15 or less 

```

Effect size and effect size plot 
In ALDEX2, the effect size is defined as a measure of the mean ratio of the difference between groups (diff.btw) and the maximum difference within groups (diff.win or variance).

```{r} 

par(mfrow = c(1,2)) 
aldex.plot(vdr_all, 
           type = "MW",
           test = "welch",
           cutoff.pval = 0.15,
           all.cex = 0.7,
           called.cex = 1.1,
           rare.col = "black",
           called.col = "red") 
aldex.plot(vdr_all, 
           type = "MW",
           test = "wilcox",
           cutoff.pval = 0.15,
           all.cex = 0.7,
           called.cex = 1.1,
           rare.col = "black",
           called.col = "red")


```

In general, p-value is less robust than effect size. Thus, researchers prefer to report effect size more often than the p-value. If sample size is sufficiently large, an effect size of 0.5 or greater is considered more likely corresponding to biological relevance. 

In ALDEX2, an effect size cutoff of 1.5 - 2 and an overlap cutoff of 0.01 is considered as more appropriate to identify differential taxa of interest. 

Here, illustrate two additional plots about effect size:
1. plot the effect size versus the p-value
2. a volcano plot to show difference between groups versus p-values 

```{r effect size plot}

par(mfrow = c(1,2)) 
plot(vdr_all$effect,
     vdr_all$wi.ep,
     log="y",
     pch=19,
     main = "Effect",
     cex=0.5,
     xlab = "Effect size",
     ylab= "Expected P value of Wilcoxon rank test") 
abline(h = 0.05, lty=2, lwd = 3, col="red") 
plot(vdr_all$diff.btw, vdr_all$wi.ep, 
     log="y",
     pch=19,
     main = "Volcano",
     cex=0.5,
     xlab="Difference",
     ylab="Expected P value of Wilcoxon rank test") 
abline(h=0.05, lty=2, lwd=3, col="red")


```



















